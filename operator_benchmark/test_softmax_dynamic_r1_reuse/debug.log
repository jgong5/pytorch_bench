[compile_fx.py:75 INFO] Compiling FORWARDS graph
[scheduler.py:564 DEBUG] Creating schedule for node: ComputedBuffer(name='buf0', layout=FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0]), data=Reduction(
  'cpu',
  torch.float32,
  load(arg0_1, r0 + i0 * s1),
  ranges=[s0, 1],
  reduction_ranges=[s1],
  reduction_type=max,
  origins={amax}
))
[scheduler.py:564 DEBUG] Creating schedule for node: ComputedBuffer(name='buf1', layout=FixedLayout('cpu', torch.float32, size=[s0, s1], stride=[s1, 1]), data=Pointwise(
  'cpu',
  torch.float32,
  exp(load(arg0_1, i1 + i0 * s1) - load(buf0, i0)),
  ranges=[s0, s1],
  origins={exp}
))
[scheduler.py:564 DEBUG] Creating schedule for node: ComputedBuffer(name='buf2', layout=FixedLayout('cpu', torch.float32, size=[s0, 1], stride=[1, s0]), data=Reduction(
  'cpu',
  torch.float32,
  load(buf1, r0 + i0 * s1),
  ranges=[s0, 1],
  reduction_ranges=[s1],
  reduction_type=sum,
  origins={sum_1}
))
[scheduler.py:564 DEBUG] Creating schedule for node: ComputedBuffer(name='buf3', layout=FixedLayout('cpu', torch.float32, size=[s0, s1], stride=[s1, 1]), data=Pointwise(
  'cpu',
  torch.float32,
  load(buf1, i1 + i0 * s1) / load(buf2, i0),
  ranges=[s0, s1],
  origins={div}
))
[cpp.py:614 DEBUG] Creating new kernel for args: ([], [])
[cpp.py:451 DEBUG] deciding parallel depth for 28 threads:
[cpp.py:459 DEBUG]   expr: s0, size_hint: 700, parallel: 1, seq: 16280600
[cpp.py:405 DEBUG] Parallel depth: 1:
[cpp.py:406 DEBUG] For(i0 in ks0, parallel 0, simd False, collapsed False, reduction_vars None)

[cpp.py:438 DEBUG] loads: auto tmp0 = in_ptr0[i1 + (i0*ks1)];

[cpp.py:439 DEBUG] compute: 
[cpp.py:440 DEBUG] stores: tmp1 = std::max(tmp1, tmp0);

[cpp.py:614 DEBUG] Creating new kernel for args: (['in_ptr0', 'out_ptr0', 'ks0', 'ks1'], ['arg0_1', 'buf0', 's0', 's1'])
[cpp.py:451 DEBUG] deciding parallel depth for 28 threads:
[cpp.py:459 DEBUG]   expr: s0, size_hint: 700, parallel: 1, seq: 16280600
[cpp.py:405 DEBUG] Parallel depth: 1:
[cpp.py:406 DEBUG] For(i0 in ks0, parallel 0, simd False, collapsed False, reduction_vars None)

[cpp.py:438 DEBUG] loads: auto tmp0 = in_ptr0[i1 + (i0*ks1)];
auto tmp1 = out_ptr0[i0];

[cpp.py:439 DEBUG] compute: auto tmp2 = tmp0 - tmp1;
auto tmp3 = std::exp(tmp2);

[cpp.py:440 DEBUG] stores: out_ptr1[i1 + (i0*ks1)] = tmp3;
tmp4 += tmp3;

[cpp.py:614 DEBUG] Creating new kernel for args: (['in_ptr0', 'out_ptr0', 'out_ptr1', 'out_ptr2', 'ks0', 'ks1'], ['arg0_1', 'buf0', 'buf1', 'buf2', 's0', 's1'])
[cpp.py:451 DEBUG] deciding parallel depth for 28 threads:
[cpp.py:459 DEBUG]   expr: s0, size_hint: 700, parallel: 1, seq: 16280600
[cpp.py:459 DEBUG]   expr: s1, size_hint: 23258, parallel: 700, seq: 23258.0
[cpp.py:405 DEBUG] Parallel depth: 1:
[cpp.py:406 DEBUG] For(i0 in ks0, parallel 0, simd False, collapsed False, reduction_vars None)
  For(i1 in ks1, parallel 0, simd True, collapsed False, reduction_vars None)

[cpp.py:438 DEBUG] loads: auto tmp0 = out_ptr1[i1 + (i0*ks1)];
auto tmp1 = out_ptr2[i0];

[cpp.py:439 DEBUG] compute: auto tmp2 = tmp0 / tmp1;

[cpp.py:440 DEBUG] stores: out_ptr3[i1 + (i0*ks1)] = tmp2;

[graph.py:336 INFO] Output code: /tmp/torchinductor_jgong5/td/ctdqwpnlwwwkt2kubnoez4qq3aqzttycjlsz342tfbrk2n3w7kz2.py
[debug.py:260 WARNING] model_inference_0 debug trace: /tmp/torchinductor_jgong5/td/ctdqwpnlwwwkt2kubnoez4qq3aqzttycjlsz342tfbrk2n3w7kz2.debug
